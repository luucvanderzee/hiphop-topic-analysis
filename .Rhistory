urls = songs$url[indices_most_representative_songs],
values = values_most_representative_songs
))
}
get_most_representative_songs(1)
get_most_representative_songs(2)
get_most_representative_songs(2)
get_most_representative_songs(17)
songs_unique <- songs_no_short_lyrics %>% distinct()
rm(list = ls())
library(DBI)
library(RSQLite)
library(tidyverse)
db_path <- "../js/genius/db/data.db"
con <- dbConnect(RSQLite::SQLite(), db_path)
table_name <- "songs"
songs <- dbReadTable(con, table_name)
dbDisconnect(con)
songs_tbl <- as_tibble(songs)
missing_entries_date_column <- which(is.na(songs_tbl$date))
new_date_column <- songs_tbl$date
new_date_column[missing_entries_date_column] <- songs_tbl$location[missing_entries_date_column]
songs_tbl_no_location <- songs_tbl %>%
select(id, artist, url, lyrics) %>%
mutate(date = new_date_column)
date_regex <- "([:digit:]{4})$"
songs_no_missing_dates <- songs_tbl_no_location %>%
filter(str_detect(date, date_regex))
songs_dates_as_years <- songs_no_missing_dates %>%
mutate(year_str = str_extract(date, date_regex)) %>%
mutate(year = as.numeric(year_str)) %>%
select(id, artist, url, lyrics, year) %>%
filter(year >= 1984)
songs_no_missing_lyrics <- songs_dates_as_years %>%
filter(!is.na(lyrics))
songs_no_short_lyrics <- songs_no_missing_lyrics %>%
mutate(length = nchar(lyrics)) %>%
filter(length > 133) %>%
select(id, artist, url, lyrics, year)
songs_unique <- songs_no_short_lyrics %>% distinct()
unique(songs_no_short_lyrics$url)
unique(songs_no_short_lyrics$url) %>% length()
?distinct
songs_no_short_lyrics %>% distinct(url) %>% nrow()
songs_unique <- songs_no_short_lyrics %>% distinct(url)
write_csv(songs_unique, "./songs.csv")
rm(list = ls())
library("quanteda", quietly = TRUE, warn.conflicts = FALSE, verbose = FALSE)
library(tidyverse)
library(topicmodels)
songs <- read_csv("./songs.csv")
songs_dfm <- songs %>%
select(id, lyrics) %>%
corpus(docid_field = "id", text_field="lyrics") %>%
dfm(remove = stopwords("en"), remove_punct = T, remove_numbers = T) %>%
dfm_trim(min_termfreq = 2)
number_of_topics <- 30
songs_lda_model <- LDA(
songs_dfm,
k = number_of_topics,
method = "Gibbs",
control = list(verbose=0L, seed = 123, burnin = 100, iter = 500)
)
rm(list = ls())
knitr::opts_chunk$set(
collapse = TRUE,
comment = "##"
)
library(DBI)
library(RSQLite)
library(tidyverse)
db_path <- "../js/genius/db/data.db"
con <- dbConnect(RSQLite::SQLite(), db_path)
table_name <- "songs"
songs <- dbReadTable(con, table_name)
dbDisconnect(con)
songs_tbl <- as_tibble(songs)
missing_entries_date_column <- which(is.na(songs_tbl$date))
new_date_column <- songs_tbl$date
new_date_column[missing_entries_date_column] <- songs_tbl$location[missing_entries_date_column]
songs_tbl_no_location <- songs_tbl %>%
select(id, artist, url, lyrics) %>%
mutate(date = new_date_column)
date_regex <- "([:digit:]{4})$"
songs_no_missing_dates <- songs_tbl_no_location %>%
filter(str_detect(date, date_regex))
# To see all the urls where the date was missing:
# songs_tbl$url[is.na(pmatch(songs_tbl$url, songs_no_missing_dates$url))]
# It seems to be predominantly more underground songs, which makes sense
songs_dates_as_years <- songs_no_missing_dates %>%
mutate(year_str = str_extract(date, date_regex)) %>%
mutate(year = as.numeric(year_str)) %>%
select(id, artist, url, lyrics, year) %>%
filter(year >= 1984) # for some reason, one year was 1901, so we removed that. From 1984 we always have at least 10 observations which seems ok.
songs_no_missing_lyrics <- songs_dates_as_years %>%
filter(!is.na(lyrics))
songs_no_short_lyrics <- songs_no_missing_lyrics %>%
mutate(length = nchar(lyrics)) %>%
filter(length > 133) %>%
select(id, artist, url, lyrics, year)
songs_unique <- songs_no_short_lyrics %>% distinct(url, .keep_all = TRUE)
write_csv(songs_unique, "./songs.csv")
rm(list = ls())
library("quanteda", quietly = TRUE, warn.conflicts = FALSE, verbose = FALSE)
library(tidyverse)
library(topicmodels)
songs <- read_csv("./songs.csv")
songs_dfm <- songs %>%
select(id, lyrics) %>%
corpus(docid_field = "id", text_field="lyrics") %>%
dfm(remove = stopwords("en"), remove_punct = T, remove_numbers = T) %>%
dfm_trim(min_termfreq = 2)
number_of_topics <- 30
songs_lda_model <- LDA(
songs_dfm,
k = number_of_topics,
method = "Gibbs",
control = list(verbose=0L, seed = 123, burnin = 100, iter = 500)
)
terms_per_topic <- get_terms(songs_lda_model, 15)
song_topic_probability_matrix <- songs_lda_model@gamma
get_most_representative_songs <- function(topic_number, number_of_songs = 5) {
topic_probability_vector <- song_topic_probability_matrix[, topic_number] %>% as.vector()
values_most_representative_songs <- sort(topic_probability_vector, decreasing = TRUE)[1:number_of_songs]
indices_most_representative_songs <- order(topic_probability_vector, decreasing = TRUE)[1:number_of_songs]
return(list(
urls = songs$url[indices_most_representative_songs],
values = values_most_representative_songs
))
}
terms_per_topic
get_most_representative_songs(22)
get_most_representative_songs(7)
rm(list = ls())
```{r, echo = FALSE}
knitr::opts_chunk$set(
collapse = TRUE,
comment = "##"
)
library(DBI)
library(RSQLite)
library(tidyverse)
db_path <- "../js/genius/db/data.db"
con <- dbConnect(RSQLite::SQLite(), db_path)
table_name <- "songs"
songs <- dbReadTable(con, table_name)
dbDisconnect(con)
songs_tbl <- as_tibble(songs)
missing_entries_date_column <- which(is.na(songs_tbl$date))
new_date_column <- songs_tbl$date
new_date_column[missing_entries_date_column] <- songs_tbl$location[missing_entries_date_column]
songs_tbl <- songs_tbl %>%
select(id, artist, url, lyrics) %>%
mutate(date = new_date_column)
date_regex <- "([:digit:]{4})$"
songs_tbl <- songs_tbl %>%
filter(str_detect(date, date_regex))
songs_tbl <- songs_tbl %>%
mutate(year_str = str_extract(date, date_regex)) %>%
mutate(year = as.numeric(year_str)) %>%
select(id, artist, url, lyrics, year) %>%
filter(year >= 1984) # for some reason, one year was 1901, so we removed that. From 1984 we always have at least 10 observations which seems ok.
songs_tbl <- songs_tbl %>%
filter(!is.na(lyrics))
songs_tbl <- songs_tbl %>%
mutate(length = nchar(lyrics)) %>%
filter(length > 133) %>%
select(id, artist, url, lyrics, year)
songs_tbl <- songs_tbl %>% distinct(url, .keep_all = TRUE)
sample(songs_tbl$)
sample(songs_tbl$url, 20)
set.seed(123)
sample(songs_tbl$url, 20)
knitr::opts_chunk$set(
collapse = TRUE,
comment = "##"
)
library(DBI)
library(RSQLite)
library(tidyverse)
db_path <- "../js/genius/db/data.db"
con <- dbConnect(RSQLite::SQLite(), db_path)
table_name <- "songs"
songs <- dbReadTable(con, table_name)
knitr::opts_chunk$set(
collapse = TRUE,
comment = "##"
)
db_path <- "../js/genius/db/data.db"
con <- dbConnect(RSQLite::SQLite(), db_path)
library(DBI)
library(RSQLite)
library(tidyverse)
db_path <- "../js/genius/db/data.db"
con <- dbConnect(RSQLite::SQLite(), db_path)
table_name <- "songs"
songs <- dbReadTable(con, table_name)
dbDisconnect(con)
songs_tbl <- as_tibble(songs)
songs_tbl <- songs_tbl %>%
filter(!is.na(lyrics))
songs_tbl <- songs_tbl %>%
mutate(length = nchar(lyrics)) %>%
filter(length > 133) %>%
select(id, artist, url, lyrics, year)
?rename
songs_tbl <- songs_tbl %>%
mutate(length = nchar(lyrics)) %>%
filter(length > 133) %>%
select(id, artist, url, lyrics, date) %>%
rename(year = date)
songs_tbl <- songs_tbl %>% distinct(url, .keep_all = TRUE)
write_csv(songs_unique, "./songs.csv")
write_csv(songs_tbl, "./songs.csv")
knitr::opts_chunk$set(
collapse = TRUE,
comment = "##"
)
library("quanteda", quietly = TRUE, warn.conflicts = FALSE, verbose = FALSE)
library("quanteda", quietly = TRUE, warn.conflicts = FALSE, verbose = FALSE)
library(tidyverse)
library(topicmodels)
rm(list = ls())
library("quanteda", quietly = TRUE, warn.conflicts = FALSE, verbose = FALSE)
library(tidyverse)
library(topicmodels)
songs <- read_csv("./songs.csv")
songs_dfm <- songs %>%
select(id, lyrics) %>%
corpus(docid_field = "id", text_field="lyrics") %>%
dfm(remove = stopwords("en"), remove_punct = T, remove_numbers = T) %>%
dfm_trim(min_termfreq = 2)
number_of_topics <- 30
songs_lda_model <- LDA(
songs_dfm,
k = number_of_topics,
method = "Gibbs",
control = list(verbose=0L, seed = 123, burnin = 100, iter = 500)
)
terms_per_topic <- get_terms(songs_lda_model, 15)
terms_per_topic
song_topic_probability_matrix <- songs_lda_model@gamma
get_most_representative_songs <- function(topic_number, number_of_songs = 5) {
topic_probability_vector <- song_topic_probability_matrix[, topic_number] %>% as.vector()
values_most_representative_songs <- sort(topic_probability_vector, decreasing = TRUE)[1:number_of_songs]
indices_most_representative_songs <- order(topic_probability_vector, decreasing = TRUE)[1:number_of_songs]
return(list(
urls = songs$url[indices_most_representative_songs],
values = values_most_representative_songs
))
}
get_most_representative_songs(25)
terms_per_topic[25]
terms_per_topic %>% names()
terms_per_topic[["Topic 25"]]
terms_per_topic["Topic 25"]
terms_per_topic[, 25]
terms_per_topic
terms_per_topic[, 30]
get_most_representative_songs(30)
terms_per_topic[, 24]
terms_per_topic[, 12]
get_most_representative_songs(12)
terms_per_topic[, 1]
get_most_representative_songs(1)
terms_per_topic[, 6]
get_most_representative_songs(6)
topic[, 15]
terms_per_topic[, 15]
terms_per_topic[, 20]
get_most_representative_songs(20)
terms_per_topic[, 11]
get_most_representative_songs(11)
get_most_representative_songs(20)
terms_per_topic[, 20]
terms_per_topic
matrix(1, 2, 3, 1, 2, 3, 1, 2, 3, byrow =T, nrow = 3) / rowSums(matrix(1, 2, 3, 1, 2, 3, 1, 2, 3, byrow =T, nrow = 3))
matrix(c(1, 2, 3, 1, 2, 3, 1, 2, 3), byrow =T, nrow = 3) / rowSums(matrix(c(1, 2, 3, 1, 2, 3, 1, 2, 3), byrow =T, nrow = 3))
relative_songs_dfm <- songs_dfm / rowSums(songs_dfm)
songs_lda_model2 <- LDA(
relative_songs_dfm,
k = number_of_topics,
method = "Gibbs",
control = list(verbose=0L, seed = 123, burnin = 100, iter = 500)
)
number_of_topics2 <- 25
songs_lda_model2 <- LDA(
relative_songs_dfm,
k = number_of_topics2,
method = "Gibbs",
control = list(verbose=0L, seed = 123, burnin = 100, iter = 500)
)
rm(relative_songs_dfm)
songs_lda_model2 <- LDA(
songs_dfm,
k = number_of_topics2,
method = "Gibbs",
control = list(verbose=0L, seed = 123, burnin = 100, iter = 500)
)
get_terms(songs_lda_model2, 15)
rm(number_of_topics2)
rm(songs_lda_model2)
terms_per_topic
get_most_representative_songs(2)
get_most_representative_songs(3)
get_most_representative_songs(4)
terms_per_topic[, 4]
terms_per_topic[, 5]
get_most_representative_songs(5)
get_most_representative_songs(5, 10)
terms_per_topic[, 7]
get_most_representative_songs(7)
terms_per_topic[, 8]
get_most_representative_songs(8)
terms_per_topic[, 9]
get_most_representative_songs(9)
terms_per_topic
terms_per_topic, 10
terms_per_topic[, 10]
get_most_representative_songs(10)
terms_per_topic[, 13]
get_most_representative_songs(13)
terms_per_topic[, 14]
get_most_representative_songs(14)
terms_per_topic[, 16]
get_most_representative_songs(16)
terms_per_topic[, 17]
get_most_representative_songs(17)
terms(songs_lda_model, 30)[, 17]
terms_per_topic[, 17]
terms_per_topic[, 18]
get_most_representative_songs(17)
get_most_representative_songs(18)
terms_per_topic[, 18]
get_most_representative_songs(17, 20)
get_most_representative_songs(15, 20)
rm(list = ls())
knitr::opts_chunk$set(
collapse = TRUE,
comment = "##"
)
library(DBI)
library(RSQLite)
library(tidyverse)
db_path <- "../js/genius/db/data.db"
con <- dbConnect(RSQLite::SQLite(), db_path)
table_name <- "songs"
songs <- dbReadTable(con, table_name)
dbDisconnect(con)
songs_tbl <- as_tibble(songs)
songs_tbl <- songs_tbl %>%
filter(!is.na(lyrics))
songs_tbl <- songs_tbl %>%
mutate(length = nchar(lyrics)) %>%
filter(length > 133) %>%
select(id, artist, url, lyrics, date) %>%
rename(year = date)
songs_tbl <- songs_tbl %>% distinct(url, .keep_all = TRUE)
foreign_language_artists <- c(
"Casper",
"Manau"
)
songs_tbl <- songs_tbl %>%
filter(!(artist %in% foreign_language_artists))
write_csv(songs_tbl, "./songs.csv")
rm(list = ls())
library("quanteda", quietly = TRUE, warn.conflicts = FALSE, verbose = FALSE)
library(tidyverse)
library(topicmodels)
songs <- read_csv("./songs.csv")
songs_dfm <- songs %>%
select(id, lyrics) %>%
corpus(docid_field = "id", text_field="lyrics") %>%
dfm(remove = stopwords("en"), remove_punct = T, remove_numbers = T) %>%
dfm_trim(min_termfreq = 2)
number_of_topics <- 30
songs_lda_model <- LDA(
songs_dfm,
k = number_of_topics,
method = "Gibbs",
control = list(verbose=0L, seed = 123, burnin = 100, iter = 500)
)
terms_per_topic <- get_terms(songs_lda_model, 15)
song_topic_probability_matrix <- songs_lda_model@gamma
get_most_representative_songs <- function(topic_number, number_of_songs = 5) {
topic_probability_vector <- song_topic_probability_matrix[, topic_number] %>% as.vector()
values_most_representative_songs <- sort(topic_probability_vector, decreasing = TRUE)[1:number_of_songs]
indices_most_representative_songs <- order(topic_probability_vector, decreasing = TRUE)[1:number_of_songs]
return(list(
urls = songs$url[indices_most_representative_songs],
values = values_most_representative_songs
))
}
terms_per_topic
get_most_representative_songs(3)
terms_per_topic[, 1]
get_most_representative_songs(1)
terms_per_topic[, 3]
get_most_representative_songs(3)
terms_per_topic[, 4]
get_most_representative_songs(4)
terms_per_topic[, 5]
get_most_representative_songs(5)
terms_per_topic[, 7]
get_most_representative_songs(8)
get_most_representative_songs(7)
terms_per_topic[, 8]
get_most_representative_songs(8)
terms_per_topic[, 9]
get_most_representative_songs(9)
terms_per_topic[, 10]
get_most_representative_songs(10)
terms_per_topic[, 12]
get_most_representative_songs(12)
terms_per_topic[, 13]
terms_per_topic[, 14]
get_most_representative_songs(14)
terms_per_topic[, 15]
get_most_representative_songs(15)
get_most_representative_songs(2)
get_most_representative_songs(1)
song_topic_probability_matrix <- songs_lda_model@gamma
topic_probability_vector <- song_topic_probability_matrix[, topic_number] %>% as.vector()
get_most_representative_songs <- function(topic_number, number_of_songs = 5) {
topic_probability_vector <- song_topic_probability_matrix[, topic_number] %>% as.vector()
values_most_representative_songs <- sort(topic_probability_vector, decreasing = TRUE)[1:number_of_songs]
indices_most_representative_songs <- order(topic_probability_vector, decreasing = TRUE)[1:number_of_songs]
return(list(
urls = songs$url[indices_most_representative_songs],
values = values_most_representative_songs
))
}
get_most_representative_songs(15)
terms_per_topic[, 15]
terms_per_topic[, 16]
get_most_representative_songs(16)
terms_per_topic
terms_per_topic[, 16]
terms_per_topic[, 18]
get_most_representative_songs(18)
terms_per_topic[, 19]
get_most_representative_songs(19)
terms_per_topic[, 20]
terms_per_topic[, 21]
get_most_representative_songs(21)
terms_per_topic[, 22]
get_most_representative_songs(22)
songs_lda_model2 <- LDA(
songs_dfm,
k = 25,
method = "Gibbs",
control = list(verbose=0L, seed = 123, burnin = 100, iter = 500)
)
terms_per_topic2 <- get_terms(songs_lda_model2, 15)
terms_per_topic2
rm(songs_lda_model2)
rm(terms_per_topic2)
terms_per_topic
get_most_representative_songs(22)
terms_per_topic[, 23]
get_most_representative_songs(23)
terms_per_topic[, 24]
get_most_representative_songs(24)
terms_per_topic[, 25]
get_most_representative_songs(25)
songs_lda_model2 <- LDA(
songs_dfm,
k = 20,
method = "Gibbs",
control = list(verbose=0L, seed = 123, burnin = 100, iter = 500)
)
terms_per_topic2 <- get_terms(songs_lda_model2, 15)
terms_per_topic2
rm(songs_lda_model2)
rm(terms_per_topic2)
dim(songs_dfm)
for (i in 1:39877) {
col <- songs_dfm[, i] %>% as.vector()
not_empty <- col != 0
if ((which(not_empty) %>% length()) == 1) {
print(i)
}
}
songs_dfm@Dimnames$features %> head()
songs_dfm$features %> head()
songs_dfm@Dimnames$features %>% head()
for (i in 1:39877) {
col <- songs_dfm[, i] %>% as.vector()
not_empty <- col != 0
if ((which(not_empty) %>% length()) == 1) {
print(songs_dfm@Dimnames$features[i])
}
}
cols_morethan1_occurance <- 1:39877 %>% sapply(function(i) {
not_empty_rows <- (songs_dfm[, i] %>% as.vector()) != 0
return((not_empty_rows %>% which() %>% length()) > 1)
})
which(cols_morethan1_occurance)
which(cols_morethan1_occurance) %>% length
songs_dfm2 <- songs_dfm2[, which(cols_morethan1_occurance)]
songs_dfm2 <- songs_dfm[, which(cols_morethan1_occurance)]
number_of_topics2 <- 30
songs_lda_model2 <- LDA(
songs_dfm2,
k = number_of_topics,
method = "Gibbs",
control = list(verbose=0L, seed = 123, burnin = 100, iter = 500)
)
terms_per_topic2 <- get_terms(songs_lda_model2, 15)
terms_per_topic2
2 + 2
2 + 2
